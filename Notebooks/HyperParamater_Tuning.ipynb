{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:42:59.271839Z",
     "start_time": "2024-10-29T15:42:57.690949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import joblib\n",
    "\n",
    "from Python_Files.predict import model\n",
    "from Python_Files.tuner import Tuner"
   ],
   "id": "4c6135fbd751e008",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-29T15:43:03.010313Z",
     "start_time": "2024-10-29T15:42:59.284915Z"
    }
   },
   "source": [
    "# Load the preprocessed dataset (replace the path with your actual file path)\n",
    "data = pd.read_csv('../data/norm_data.csv')\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.copy()\n",
    "y = X.pop('label')\n",
    "\n",
    "# Split the dataset into training and test sets (using only 25% of the data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "joblib.dump(scaler, '../models/scaler.pkl')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/scaler.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analysis of logisitc regression\n",
    "\n",
    "## Default Model:  \n",
    "- Trains a Logistic Regression model with default settings.\n",
    "- Evaluates the model on the test data.\n",
    "\n",
    "## Tuned Model:  \n",
    "\n",
    "- Uses GridSearchCV to find the best settings (hyperparameters) for the Logistic Regression model.\n",
    "- Trains the model with these best settings.\n",
    "- Evaluates the tuned model on the test data.\n",
    "\n",
    "## Cross-Validation:  \n",
    "\n",
    "- Checks the average performance of both the default and tuned models using cross-validation (splitting the data into 5 parts and training/testing on each part).\n",
    "\n",
    "## Results:  \n",
    "\n",
    "\n",
    "### Default Model:  \n",
    "- Accuracy: 0.999978 \n",
    "\n",
    "### Tuned Model:  \n",
    "- Accuracy: 0.999990 (slightly better than default)\n",
    "\n",
    "### Cross-Validation:  \n",
    "- Default model average accuracy: 0.999941\n",
    "- Tuned model average accuracy: 0.999975\n",
    "- Both models perform extremely well, with the tuned model being slightly better."
   ],
   "id": "c3add20a576c5e2b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create the tuner class",
   "id": "4a6b80b607907d73"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:43:08.194586Z",
     "start_time": "2024-10-29T15:43:06.795955Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_log_reg = Tuner(LogisticRegression(max_iter=1000), X_train, X_test, y_train, y_test)",
   "id": "30f69de6693cbb69",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluate the default model",
   "id": "e65c6b6ed1fb6705"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:44:16.140499Z",
     "start_time": "2024-10-29T15:43:08.207110Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_log_reg.evaluate()",
   "id": "fcb23f22ddd4934b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default model accuracy:\n",
      "\t0.9999610665420796\n",
      "Default model Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  legitimate       1.00      1.00      1.00    937571\n",
      "    phishing       1.00      1.00      1.00    937423\n",
      "\n",
      "    accuracy                           1.00   1874994\n",
      "   macro avg       1.00      1.00      1.00   1874994\n",
      "weighted avg       1.00      1.00      1.00   1874994\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:44:23.406180Z",
     "start_time": "2024-10-29T15:44:16.166945Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_log_reg.confusion_matrix()",
   "id": "af715a03ae25a5ac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "tune the model",
   "id": "d3b4917b75087639"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:56:17.781378Z",
     "start_time": "2024-10-25T13:55:40.444399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid_log_reg = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "tuner_log_reg.tune(param_grid=param_grid_log_reg)"
   ],
   "id": "8395f3da89baa950",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluate the best model",
   "id": "19eb9c3a1cc467d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:57:25.379677Z",
     "start_time": "2024-10-25T13:56:17.795117Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_log_reg.evaluate(model='best')",
   "id": "a33bea1e05e7702d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model accuracy:\n",
      "\t0.9999797332684798\n",
      "Best model Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  legitimate       1.00      1.00      1.00    937571\n",
      "    phishing       1.00      1.00      1.00    937423\n",
      "\n",
      "    accuracy                           1.00   1874994\n",
      "   macro avg       1.00      1.00      1.00   1874994\n",
      "weighted avg       1.00      1.00      1.00   1874994\n",
      "\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tuner_log_reg.confusion_matrix(model='best')",
   "id": "8cf5ecc5c2e8ada0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Perform cross validation",
   "id": "841da96d719b5c3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:57:28.184505Z",
     "start_time": "2024-10-25T13:57:25.393366Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_log_reg.cross_validation()",
   "id": "46af7b2f78e62523",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default model Cross-Validation accuracy:\n",
      "\t0.9999471998463987\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:57:36.756909Z",
     "start_time": "2024-10-25T13:57:28.207713Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_log_reg.cross_validation(model='best')",
   "id": "6691b7bf4dbdfe11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model Cross-Validation accuracy:\n",
      "\t0.9999759999359995\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analysis of Decision Tree\n",
    "\n",
    "## Default Model:\n",
    "\n",
    "- Trains a Decision Tree model with default settings.\n",
    "- Evaluates the model on the test data.\n",
    "\n",
    "## Tuned Model:\n",
    "\n",
    "- Uses GridSearchCV to find the best settings (hyperparameters) for the Decision Tree model.\n",
    "- Trains the model with these best settings.\n",
    "- Evaluates the tuned model on the test data.\n",
    "\n",
    "## Cross-Validation:\n",
    "- Checks the average performance of both the default and tuned models using cross-validation (splitting the data into 5 parts and training/testing on each part).\n",
    "\n",
    "## Results:\n",
    "Default Model:\n",
    "- Accuracy: 0.999972\n",
    "-  Detailed report shows precision, recall, and F1-score all close to 1.00 for both classes (0 and 1)\n",
    "\n",
    "Tuned Model:\n",
    "- Accuracy: 0.999972 (same as default)\n",
    "- Detailed report shows precision, recall, and F1-score all close to 1.00 for both classes (0 and 1)\n",
    "\n",
    "Cross-Validation:\n",
    "- Default model average accuracy: 0.999985\n",
    "- Tuned model average accuracy: 0.999986"
   ],
   "id": "66fa297aac147f2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create the tuner class",
   "id": "8b405472d18196c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:15:24.837052Z",
     "start_time": "2024-10-25T12:15:22.766924Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_tree_clf = Tuner(DecisionTreeClassifier(), X_train, X_test, y_train, y_test)",
   "id": "cf0f3e83edcb77a3",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluate the default model",
   "id": "dbedc6a932af3e4a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:16:34.886630Z",
     "start_time": "2024-10-25T12:15:26.575650Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_tree_clf.evaluate()",
   "id": "652abf903b46b4a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default model accuracy:\n",
      "\t0.9999429331507195\n",
      "Default model Report:\n",
      "\t              precision    recall  f1-score   support\n",
      "\n",
      "  legitimate       1.00      1.00      1.00    937571\n",
      "    phishing       1.00      1.00      1.00    937423\n",
      "\n",
      "    accuracy                           1.00   1874994\n",
      "   macro avg       1.00      1.00      1.00   1874994\n",
      "weighted avg       1.00      1.00      1.00   1874994\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tuner_tree_clf.confusion_matrix()",
   "id": "2be0d6c0e5d77c27"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "tune the model",
   "id": "485dcbe9eb52ebd5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:17:00.704751Z",
     "start_time": "2024-10-25T12:16:38.143740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid_tree_clf = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "tuner_tree_clf.tune(param_grid=param_grid_tree_clf)"
   ],
   "id": "c251683016c7a1f5",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluate the best model",
   "id": "d124b1a5d31be20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:18:16.963574Z",
     "start_time": "2024-10-25T12:17:08.786837Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_tree_clf.evaluate(model='best')",
   "id": "da773e241b8bf0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model accuracy:\n",
      "\t0.9999541331865596\n",
      "Best model Report:\n",
      "\t              precision    recall  f1-score   support\n",
      "\n",
      "  legitimate       1.00      1.00      1.00    937571\n",
      "    phishing       1.00      1.00      1.00    937423\n",
      "\n",
      "    accuracy                           1.00   1874994\n",
      "   macro avg       1.00      1.00      1.00   1874994\n",
      "weighted avg       1.00      1.00      1.00   1874994\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tuner_tree_clf.confusion_matrix(model='best')",
   "id": "7d93d89d4ff651a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Perform cross validation",
   "id": "a3204e2cc608a3b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:18:20.519147Z",
     "start_time": "2024-10-25T12:18:16.971090Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_tree_clf.cross_validation()",
   "id": "52606270a99210fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default model Cross-Validation accuracy:\n",
      "\t0.9999567998207987\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:18:24.151064Z",
     "start_time": "2024-10-25T12:18:20.587472Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_tree_clf.cross_validation(model='best')",
   "id": "fdec006dd72102cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model Cross-Validation accuracy:\n",
      "\t0.9999551998335987\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analysis of Random Forest\n",
    "### Default Model:\n",
    "- Trains a Random Forest model with default settings.\n",
    "- Evaluates the model on the test data.\n",
    "\n",
    "### Tuned Model:\n",
    "- Uses GridSearchCV to find the best settings (hyperparameters) for the Random Forest model.\n",
    "- Trains the model with these best settings.\n",
    "- Evaluates the tuned model on the test data.\n",
    "### Cross-Validation:\n",
    "- Checks the average performance of both the default and tuned models using cross-validation (splitting the data into 3 parts and training/testing on each part).\n",
    "## Results:\n",
    "\n",
    "### Default Model:\n",
    "- Accuracy: 0.999991\n",
    "\n",
    "### Tuned Model:\n",
    "- Accuracy: 0.999992 (slightly better than default)\n"
   ],
   "id": "c8fa3ef91cf5c4b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create the tuner class",
   "id": "b1a212d6aea7140a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:17:48.206647Z",
     "start_time": "2024-10-25T13:17:07.151795Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_rf_clf = Tuner(RandomForestClassifier(), X_train, X_test, y_train, y_test)",
   "id": "704c70f5b175f933",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluate the default model",
   "id": "5c8dc7a5391b6a40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:19:03.253996Z",
     "start_time": "2024-10-25T13:17:48.211654Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_rf_clf.evaluate()",
   "id": "20312e9e1df5e620",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default model accuracy:\n",
      "\t0.99999626665472\n",
      "Default model Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  legitimate       1.00      1.00      1.00    937571\n",
      "    phishing       1.00      1.00      1.00    937423\n",
      "\n",
      "    accuracy                           1.00   1874994\n",
      "   macro avg       1.00      1.00      1.00   1874994\n",
      "weighted avg       1.00      1.00      1.00   1874994\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tuner_rf_clf.confusion_matrix()",
   "id": "d01e5f2e52aa60db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "tune the model",
   "id": "483919586f25e9b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:28:07.077571Z",
     "start_time": "2024-10-25T13:19:03.293054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid_rf_clf = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "tuner_rf_clf.tune(param_grid=param_grid_rf_clf)"
   ],
   "id": "6ed2689b84f94b92",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluate the best model",
   "id": "579ffef11e323e7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:29:17.978455Z",
     "start_time": "2024-10-25T13:28:07.092378Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_rf_clf.evaluate(model='best')",
   "id": "9c474a41881237c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model accuracy:\n",
      "\t0.9999909333043199\n",
      "Best model Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  legitimate       1.00      1.00      1.00    937571\n",
      "    phishing       1.00      1.00      1.00    937423\n",
      "\n",
      "    accuracy                           1.00   1874994\n",
      "   macro avg       1.00      1.00      1.00   1874994\n",
      "weighted avg       1.00      1.00      1.00   1874994\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tuner_rf_clf.confusion_matrix(model='best')",
   "id": "21df191344a40306"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Perform cross validation",
   "id": "f93b4d4c5a5f399b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:29:53.730361Z",
     "start_time": "2024-10-25T13:29:17.992078Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_rf_clf.cross_validation(cv=3)",
   "id": "8fb368619841e418",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default model Cross-Validation accuracy:\n",
      "\t0.9999935999820799\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:30:13.211001Z",
     "start_time": "2024-10-25T13:29:53.745821Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_rf_clf.cross_validation(model='best', cv=3)",
   "id": "c932cb7d7b08f131",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model Cross-Validation accuracy:\n",
      "\t0.9999903999769599\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analysis of SVM\n",
    "### Default Model:\n",
    "- Trains an SVM model with default settings.\n",
    "- Evaluates the model on the test data.\n",
    "### Tuned Model:\n",
    "- Uses GridSearchCV to find the best settings (hyperparameters) for the SVM model.\n",
    "- Trains the model with these best settings.\n",
    "= Evaluates the tuned model on the test data.\n",
    "### Cross-Validation:\n",
    "- Checks the average performance of both the default and tuned models using cross-validation (splitting the data into 3 parts and training/testing on each part).\n",
    "\n",
    "## Results:\n",
    "\n",
    "### Default Model:  \n",
    "- Accuracy: 0.999976\n",
    "- Detailed report shows precision, recall, and F1-score all close to 1.00 for both classes (0 and 1)\n",
    "### Tuned Model:  \n",
    "- Accuracy: 0.999987 (slightly better than default)\n",
    "- Detailed report shows precision, recall, and F1-score all close to 1.00 for both classes (0 and 1)\n",
    "### Cross-Validation:\n",
    "- Default model average accuracy: 0.999976\n",
    "- Tuned model average accuracy: 0.999979"
   ],
   "id": "5b36d57956e58c00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create the tuner class",
   "id": "66f7c0e78a6a5530"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:38:18.427312Z",
     "start_time": "2024-10-25T12:37:02.227215Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_svm_clf = Tuner(SVC(), X_train, X_test, y_train, y_test)",
   "id": "395dc4115e121152",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluate the default model",
   "id": "686f14c7580c1b52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:41:47.175743Z",
     "start_time": "2024-10-25T12:38:18.432323Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_svm_clf.evaluate()",
   "id": "c30b612ab3c9f802",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default model accuracy:\n",
      "\t0.9999775999283198\n",
      "Default model Report:\n",
      "\t              precision    recall  f1-score   support\n",
      "\n",
      "  legitimate       1.00      1.00      1.00    937571\n",
      "    phishing       1.00      1.00      1.00    937423\n",
      "\n",
      "    accuracy                           1.00   1874994\n",
      "   macro avg       1.00      1.00      1.00   1874994\n",
      "weighted avg       1.00      1.00      1.00   1874994\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tuner_svm_clf.confusion_matrix()",
   "id": "cd24b9804398e66a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "tune the model",
   "id": "1593a9d6f2d7d69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:58:46.413008Z",
     "start_time": "2024-10-25T12:51:42.911204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid_svm_clf = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "tuner_svm_clf.tune(param_grid=param_grid_svm_clf, verbose=3)"
   ],
   "id": "2aaeabbcabe8aff1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluate the best model",
   "id": "8268f264d2b32db7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:01:50.259098Z",
     "start_time": "2024-10-25T12:58:46.428464Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_svm_clf.evaluate(model='best')",
   "id": "922df4734dfc304c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model accuracy:\n",
      "\t0.9999877332940799\n",
      "Best model Report:\n",
      "\t              precision    recall  f1-score   support\n",
      "\n",
      "  legitimate       1.00      1.00      1.00    937571\n",
      "    phishing       1.00      1.00      1.00    937423\n",
      "\n",
      "    accuracy                           1.00   1874994\n",
      "   macro avg       1.00      1.00      1.00   1874994\n",
      "weighted avg       1.00      1.00      1.00   1874994\n",
      "\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tuner_svm_clf.confusion_matrix(model='best')",
   "id": "10abc3546a368119"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Perform cross validation",
   "id": "321ce3afba3fd143"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:06:28.949952Z",
     "start_time": "2024-10-25T13:01:50.274306Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_svm_clf.cross_validation(cv=3)",
   "id": "c5ab72d2f9b9f8d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default model Cross-Validation accuracy:\n",
      "\t0.9999759999385597\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:08:02.088927Z",
     "start_time": "2024-10-25T13:06:29.029710Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_svm_clf.cross_validation(model='best', cv=3)",
   "id": "d6fb38fa81fc1497",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model Cross-Validation accuracy:\n",
      "\t0.9999839999667198\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analysis of Bad Model\n",
    "\n",
    "Here i created a worse model by having a decision tree with a max depth of 1. This model is expected to perform poorly compared to the other models.\n",
    "Then i use hyperparameter tuning to improve the model and compare the results with the tuned model. This gives a more noticable imporvement in the model. Compared to the other models, the bad model has a lower accuracy and F1-score."
   ],
   "id": "15bb218bfb59678c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:09:52.762208Z",
     "start_time": "2024-10-25T13:09:39.209669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.copy()\n",
    "y = X.pop('label')\n",
    "\n",
    "# Convert the target labels to binary format\n",
    "y = y.map({'phishing': 1, 'legitimate': 0})\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the Decision Tree classifier with limited depth\n",
    "bad_model = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# Train the bad model with default parameters\n",
    "bad_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the bad model\n",
    "bad_model_pred = bad_model.predict(X_test)\n",
    "print(\"Bad Model Accuracy: \", accuracy_score(y_test, bad_model_pred))\n",
    "print(\"Bad Model Report:\\n\", classification_report(y_test, bad_model_pred, zero_division=0))\n",
    "\n",
    "# Perform cross-validation on the bad model\n",
    "bad_model_scores = cross_val_score(bad_model, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "print(\"Bad Model Cross-Validation Accuracy: \", bad_model_scores.mean())\n",
    "\n",
    "# Define parameter grid for DecisionTreeClassifier\n",
    "param_grid_tree = {\n",
    "    'max_depth': [1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with DecisionTreeClassifier\n",
    "grid_tree_clf = GridSearchCV(DecisionTreeClassifier(), param_grid_tree, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_tree_clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from GridSearchCV\n",
    "best_tree_clf = grid_tree_clf.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "tree_clf_pred = best_tree_clf.predict(X_test)\n",
    "print(\"Tuned Decision Tree Accuracy: \", accuracy_score(y_test, tree_clf_pred))\n",
    "print(\"Tuned Decision Tree Report:\\n\", classification_report(y_test, tree_clf_pred, zero_division=0))\n",
    "\n",
    "# Perform cross-validation on the tuned model\n",
    "tuned_tree_scores = cross_val_score(best_tree_clf, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "print(\"Tuned Decision Tree Cross-Validation Accuracy: \", tuned_tree_scores.mean())"
   ],
   "id": "ee2fbb1777d959",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad Model Accuracy:  0.9440830210656674\n",
      "Bad Model Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95    937571\n",
      "           1       0.97      0.92      0.94    937423\n",
      "\n",
      "    accuracy                           0.94   1874994\n",
      "   macro avg       0.95      0.94      0.94   1874994\n",
      "weighted avg       0.95      0.94      0.94   1874994\n",
      "\n",
      "Bad Model Cross-Validation Accuracy:  0.9444814224196278\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 45\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;66;03m# Initialize GridSearchCV with DecisionTreeClassifier\u001B[39;00m\n\u001B[0;32m     44\u001B[0m grid_tree_clf \u001B[38;5;241m=\u001B[39m GridSearchCV(DecisionTreeClassifier(), param_grid_tree, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 45\u001B[0m \u001B[43mgrid_tree_clf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# Get the best model from GridSearchCV\u001B[39;00m\n\u001B[0;32m     48\u001B[0m best_tree_clf \u001B[38;5;241m=\u001B[39m grid_tree_clf\u001B[38;5;241m.\u001B[39mbest_estimator_\n",
      "File \u001B[1;32m~\\.venvs\\AI3\\Lib\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.venvs\\AI3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m   1013\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m   1014\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m   1015\u001B[0m     )\n\u001B[0;32m   1017\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m-> 1019\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1021\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m   1022\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m   1023\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\.venvs\\AI3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1571\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1572\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1573\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.venvs\\AI3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    957\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    958\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    959\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    960\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    961\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    962\u001B[0m         )\n\u001B[0;32m    963\u001B[0m     )\n\u001B[1;32m--> 965\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    966\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    967\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    968\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    969\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    970\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    971\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    973\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    974\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    975\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    976\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    977\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    978\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    979\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    980\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    981\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    983\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    984\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    985\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    986\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    987\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    988\u001B[0m     )\n",
      "File \u001B[1;32m~\\.venvs\\AI3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     69\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     70\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     71\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     73\u001B[0m )\n\u001B[1;32m---> 74\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.venvs\\AI3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   2001\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   2002\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   2003\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[0;32m   2004\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   2005\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 2007\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.venvs\\AI3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1647\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1649\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1650\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1653\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1654\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1655\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1656\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\.venvs\\AI3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1757\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1758\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[0;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1760\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1761\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1762\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1763\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m   1765\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[0;32m   1766\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[0;32m   1767\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save the best model",
   "id": "ed6a613c5e688986"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:47:27.919236Z",
     "start_time": "2024-10-25T13:47:27.898765Z"
    }
   },
   "cell_type": "code",
   "source": "tuner_rf_clf.save_best_model(model_path='../models/random_forest.pkl')",
   "id": "6dc7c890558913b2",
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
