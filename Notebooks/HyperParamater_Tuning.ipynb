{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:04:36.832164Z",
     "start_time": "2024-10-22T14:04:33.661518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score"
   ],
   "id": "4c6135fbd751e008",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-22T15:26:21.225748Z",
     "start_time": "2024-10-22T15:26:13.962800Z"
    }
   },
   "source": [
    "\n",
    "# Load the preprocessed dataset (replace the path with your actual file path)\n",
    "data = pd.read_csv('../data/norm_data.csv')\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.copy()\n",
    "y = X.pop('label')\n",
    "\n",
    "# Remove the 'url' column as it is not a feature\n",
    "X.pop('url')\n",
    "\n",
    "# Convert the target labels to binary format\n",
    "y = y.map({'phishing': 1, 'legitimate': 0})\n",
    "\n",
    "# Split the dataset into training and test sets (using only 25% of the data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the models\n",
    "log_reg = LogisticRegression(max_iter=1000)  # Increased max_iter\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "rf_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "param_grid_tree_clf = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "param_grid_rf_clf = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "param_grid_svm_clf = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analysis of logisitc regression\n",
    "\n",
    "## Default Model:  \n",
    "- Trains a Logistic Regression model with default settings.\n",
    "- Evaluates the model on the test data.\n",
    "\n",
    "## Tuned Model:  \n",
    "\n",
    "- Uses GridSearchCV to find the best settings (hyperparameters) for the Logistic Regression model.\n",
    "- Trains the model with these best settings.\n",
    "- Evaluates the tuned model on the test data.\n",
    "\n",
    "## Cross-Validation:  \n",
    "\n",
    "- Checks the average performance of both the default and tuned models using cross-validation (splitting the data into 5 parts and training/testing on each part).\n",
    "\n",
    "## Results:  \n",
    "\n",
    "\n",
    "### Default Model:  \n",
    "- Accuracy: 0.999978 \n",
    "\n",
    "### Tuned Model:  \n",
    "- Accuracy: 0.999990 (slightly better than default)\n",
    "\n",
    "### Cross-Validation:  \n",
    "- Default model average accuracy: 0.999941\n",
    "- Tuned model average accuracy: 0.999975\n",
    "- Both models perform extremely well, with the tuned model being slightly better."
   ],
   "id": "c3add20a576c5e2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T15:27:25.689058Z",
     "start_time": "2024-10-22T15:26:29.911418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the Logistic Regression model with default parameters\n",
    "default_log_reg = LogisticRegression(max_iter=1000)\n",
    "default_log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the default model\n",
    "default_log_reg_pred = default_log_reg.predict(X_test)\n",
    "print(\"Default Logistic Regression Accuracy: \", accuracy_score(y_test, default_log_reg_pred))\n",
    "print(\"Default Logistic Regression Report:\\n\", classification_report(y_test, default_log_reg_pred))\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning with parallelization\n",
    "param_grid_log_reg = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "grid_log_reg = GridSearchCV(LogisticRegression(max_iter=1000), param_grid_log_reg, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from GridSearchCV\n",
    "best_log_reg = grid_log_reg.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "log_reg_pred = best_log_reg.predict(X_test)\n",
    "print(\"Tuned Logistic Regression Accuracy: \", accuracy_score(y_test, log_reg_pred))\n",
    "print(\"Tuned Logistic Regression Report:\\n\", classification_report(y_test, log_reg_pred))\n",
    "\n",
    "\n",
    "# Perform cross-validation on the default model\n",
    "default_scores = cross_val_score(default_log_reg, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "print(\"Default Logistic Regression Cross-Validation Accuracy: \", default_scores.mean())\n",
    "\n",
    "# Perform cross-validation on the tuned model\n",
    "tuned_scores = cross_val_score(best_log_reg, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "print(\"Tuned Logistic Regression Cross-Validation Accuracy: \", tuned_scores.mean())"
   ],
   "id": "4c97da5666a86601",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Logistic Regression Accuracy:  0.9999615998771196\n",
      "Default Logistic Regression Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    937118\n",
      "           1       1.00      1.00      1.00    937876\n",
      "\n",
      "    accuracy                           1.00   1874994\n",
      "   macro avg       1.00      1.00      1.00   1874994\n",
      "weighted avg       1.00      1.00      1.00   1874994\n",
      "\n",
      "Tuned Logistic Regression Accuracy:  0.9999738665830398\n",
      "Tuned Logistic Regression Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    937118\n",
      "           1       1.00      1.00      1.00    937876\n",
      "\n",
      "    accuracy                           1.00   1874994\n",
      "   macro avg       1.00      1.00      1.00   1874994\n",
      "weighted avg       1.00      1.00      1.00   1874994\n",
      "\n",
      "Default Logistic Regression Cross-Validation Accuracy:  0.9999503998207986\n",
      "Tuned Logistic Regression Cross-Validation Accuracy:  0.9999759999103993\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analysis of Decision Tree\n",
    "\n",
    "## Default Model:\n",
    "\n",
    "- Trains a Decision Tree model with default settings.\n",
    "- Evaluates the model on the test data.\n",
    "\n",
    "## Tuned Model:\n",
    "\n",
    "- Uses GridSearchCV to find the best settings (hyperparameters) for the Decision Tree model.\n",
    "- Trains the model with these best settings.\n",
    "- Evaluates the tuned model on the test data.\n",
    "\n",
    "## Cross-Validation:\n",
    "- Checks the average performance of both the default and tuned models using cross-validation (splitting the data into 5 parts and training/testing on each part).\n",
    "\n",
    "## Results:\n",
    "Default Model:\n",
    "- Accuracy: 0.999972\n",
    "-  Detailed report shows precision, recall, and F1-score all close to 1.00 for both classes (0 and 1)\n",
    "\n",
    "Tuned Model:\n",
    "- Accuracy: 0.999972 (same as default)\n",
    "- Detailed report shows precision, recall, and F1-score all close to 1.00 for both classes (0 and 1)\n",
    "\n",
    "Cross-Validation:\n",
    "- Default model average accuracy: 0.999985\n",
    "- Tuned model average accuracy: 0.999986"
   ],
   "id": "66fa297aac147f2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T15:28:27.547633Z",
     "start_time": "2024-10-22T15:27:50.403048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the Decision Tree model with default parameters\n",
    "default_tree_clf = DecisionTreeClassifier()\n",
    "default_tree_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the default model\n",
    "default_tree_clf_pred = default_tree_clf.predict(X_test)\n",
    "print(\"Default Decision Tree Accuracy: \", accuracy_score(y_test, default_tree_clf_pred))\n",
    "print(\"Default Decision Tree Report:\\n\", classification_report(y_test, default_tree_clf_pred))\n",
    "\n",
    "grid_tree_clf = GridSearchCV(DecisionTreeClassifier(), param_grid_tree_clf, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_tree_clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from GridSearchCV\n",
    "best_tree_clf = grid_tree_clf.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "tree_clf_pred = best_tree_clf.predict(X_test)\n",
    "print(\"Tuned Decision Tree Accuracy: \", accuracy_score(y_test, tree_clf_pred))\n",
    "print(\"Tuned Decision Tree Report:\\n\", classification_report(y_test, tree_clf_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Perform cross-validation on the default model\n",
    "default_tree_scores = cross_val_score(default_tree_clf, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "print(\"Default Decision Tree Cross-Validation Accuracy: \", default_tree_scores.mean())\n",
    "\n",
    "# Perform cross-validation on the tuned model\n",
    "tuned_tree_scores = cross_val_score(best_tree_clf, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "print(\"Tuned Decision Tree Cross-Validation Accuracy: \", tuned_tree_scores.mean())"
   ],
   "id": "d37b9edbb9d9b2bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Decision Tree Accuracy:  0.9999685332326397\n",
      "Default Decision Tree Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    937118\n",
      "           1       1.00      1.00      1.00    937876\n",
      "\n",
      "    accuracy                           1.00   1874994\n",
      "   macro avg       1.00      1.00      1.00   1874994\n",
      "weighted avg       1.00      1.00      1.00   1874994\n",
      "\n",
      "Tuned Decision Tree Accuracy:  0.9999722665779197\n",
      "Tuned Decision Tree Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    937118\n",
      "           1       1.00      1.00      1.00    937876\n",
      "\n",
      "    accuracy                           1.00   1874994\n",
      "   macro avg       1.00      1.00      1.00   1874994\n",
      "weighted avg       1.00      1.00      1.00   1874994\n",
      "\n",
      "Default Decision Tree Cross-Validation Accuracy:  0.9999567997823983\n",
      "Tuned Decision Tree Cross-Validation Accuracy:  0.9999679998463987\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# \n",
    "# \n",
    "\n",
    "\n"
   ],
   "id": "8a181c4b2199e790"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T15:43:45.922072Z",
     "start_time": "2024-10-22T15:28:47.679337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the Random Forest model with default parameters\n",
    "default_rf_clf = RandomForestClassifier()\n",
    "default_rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the default model\n",
    "default_rf_clf_pred = default_rf_clf.predict(X_test)\n",
    "print(\"Default Random Forest Accuracy: \", accuracy_score(y_test, default_rf_clf_pred))\n",
    "print(\"Default Random Forest Report:\\n\", classification_report(y_test, default_rf_clf_pred))\n",
    "\n",
    "\n",
    "grid_rf_clf = GridSearchCV(RandomForestClassifier(), param_grid_rf_clf, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from GridSearchCV\n",
    "best_rf_clf = grid_rf_clf.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "rf_clf_pred = best_rf_clf.predict(X_test)\n",
    "print(\"Tuned Random Forest Accuracy: \", accuracy_score(y_test, rf_clf_pred))\n",
    "print(\"Tuned Random Forest Report:\\n\", classification_report(y_test, rf_clf_pred))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation on the default model\n",
    "default_rf_scores = cross_val_score(default_rf_clf, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "print(\"Default Random Forest Cross-Validation Accuracy: \", default_rf_scores.mean())\n",
    "\n",
    "# Perform cross-validation on the tuned model\n",
    "tuned_rf_scores = cross_val_score(best_rf_clf, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "print(\"Tuned Random Forest Cross-Validation Accuracy: \", tuned_rf_scores.mean())"
   ],
   "id": "f17fd26b61934a69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Random Forest Accuracy:  0.9999909333043199\n",
      "Default Random Forest Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    937118\n",
      "           1       1.00      1.00      1.00    937876\n",
      "\n",
      "    accuracy                           1.00   1874994\n",
      "   macro avg       1.00      1.00      1.00   1874994\n",
      "weighted avg       1.00      1.00      1.00   1874994\n",
      "\n",
      "Tuned Random Forest Accuracy:  0.9999919999743999\n",
      "Tuned Random Forest Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    937118\n",
      "           1       1.00      1.00      1.00    937876\n",
      "\n",
      "    accuracy                           1.00   1874994\n",
      "   macro avg       1.00      1.00      1.00   1874994\n",
      "weighted avg       1.00      1.00      1.00   1874994\n",
      "\n",
      "Default Random Forest Cross-Validation Accuracy:  0.9999935999667198\n",
      "Tuned Random Forest Cross-Validation Accuracy:  0.9999935999743998\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T16:06:49.484923Z",
     "start_time": "2024-10-22T15:45:56.290926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the SVM classifier\n",
    "default_svm_clf = SVC()\n",
    "\n",
    "# Train the SVM model with default parameters\n",
    "default_svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the default model\n",
    "default_svm_clf_pred = default_svm_clf.predict(X_test)\n",
    "print(\"Default SVM Accuracy: \", accuracy_score(y_test, default_svm_clf_pred))\n",
    "print(\"Default SVM Report:\\n\", classification_report(y_test, default_svm_clf_pred))\n",
    "\n",
    "# Define parameter grid for SVM\n",
    "param_grid_svm_clf = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with SVM classifier\n",
    "grid_svm_clf = GridSearchCV(SVC(), param_grid_svm_clf, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from GridSearchCV\n",
    "best_svm_clf = grid_svm_clf.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "svm_clf_pred = best_svm_clf.predict(X_test)\n",
    "print(\"Tuned SVM Accuracy: \", accuracy_score(y_test, svm_clf_pred))\n",
    "print(\"Tuned SVM Report:\\n\", classification_report(y_test, svm_clf_pred))\n",
    "\n",
    "# Perform cross-validation on the default model\n",
    "default_svm_scores = cross_val_score(default_svm_clf, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "print(\"Default SVM Cross-Validation Accuracy: \", default_svm_scores.mean())\n",
    "\n",
    "# Perform cross-validation on the tuned model\n",
    "tuned_svm_scores = cross_val_score(best_svm_clf, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "print(\"Tuned SVM Cross-Validation Accuracy: \", tuned_svm_scores.mean())"
   ],
   "id": "305661862ef209c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default SVM Accuracy:  0.9999759999231997\n",
      "Default SVM Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    937118\n",
      "           1       1.00      1.00      1.00    937876\n",
      "\n",
      "    accuracy                           1.00   1874994\n",
      "   macro avg       1.00      1.00      1.00   1874994\n",
      "weighted avg       1.00      1.00      1.00   1874994\n",
      "\n",
      "Tuned SVM Accuracy:  0.9999866666239998\n",
      "Tuned SVM Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    937118\n",
      "           1       1.00      1.00      1.00    937876\n",
      "\n",
      "    accuracy                           1.00   1874994\n",
      "   macro avg       1.00      1.00      1.00   1874994\n",
      "weighted avg       1.00      1.00      1.00   1874994\n",
      "\n",
      "Default SVM Cross-Validation Accuracy:  0.9999759999231997\n",
      "Tuned SVM Cross-Validation Accuracy:  0.9999791999513598\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analysis of Bad Model\n",
    "\n",
    "Here i created a worse model by having a decision tree with a max depth of 1. This model is expected to perform poorly compared to the other models.\n",
    "Then i use hyperparameter tuning to improve the model and compare the results with the tuned model. This gives a more noticable imporvement in the model. Compared to the other models, the bad model has a lower accuracy and F1-score."
   ],
   "id": "15bb218bfb59678c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T16:18:49.297528Z",
     "start_time": "2024-10-22T16:18:22.306201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.copy()\n",
    "y = X.pop('label')\n",
    "\n",
    "# Remove the 'url' column as it is not a feature\n",
    "X.pop('url')\n",
    "\n",
    "# Convert the target labels to binary format\n",
    "y = y.map({'phishing': 1, 'legitimate': 0})\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the Decision Tree classifier with limited depth\n",
    "bad_model = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# Train the bad model with default parameters\n",
    "bad_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the bad model\n",
    "bad_model_pred = bad_model.predict(X_test)\n",
    "print(\"Bad Model Accuracy: \", accuracy_score(y_test, bad_model_pred))\n",
    "print(\"Bad Model Report:\\n\", classification_report(y_test, bad_model_pred, zero_division=0))\n",
    "\n",
    "# Perform cross-validation on the bad model\n",
    "bad_model_scores = cross_val_score(bad_model, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "print(\"Bad Model Cross-Validation Accuracy: \", bad_model_scores.mean())\n",
    "\n",
    "# Define parameter grid for DecisionTreeClassifier\n",
    "param_grid_tree = {\n",
    "    'max_depth': [1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with DecisionTreeClassifier\n",
    "grid_tree_clf = GridSearchCV(DecisionTreeClassifier(), param_grid_tree, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_tree_clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from GridSearchCV\n",
    "best_tree_clf = grid_tree_clf.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "tree_clf_pred = best_tree_clf.predict(X_test)\n",
    "print(\"Tuned Decision Tree Accuracy: \", accuracy_score(y_test, tree_clf_pred))\n",
    "print(\"Tuned Decision Tree Report:\\n\", classification_report(y_test, tree_clf_pred, zero_division=0))\n",
    "\n",
    "# Perform cross-validation on the tuned model\n",
    "tuned_tree_scores = cross_val_score(best_tree_clf, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "print(\"Tuned Decision Tree Cross-Validation Accuracy: \", tuned_tree_scores.mean())"
   ],
   "id": "ee2fbb1777d959",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad Model Accuracy:  0.9442648883143093\n",
      "Bad Model Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95    937118\n",
      "           1       0.97      0.92      0.94    937876\n",
      "\n",
      "    accuracy                           0.94   1874994\n",
      "   macro avg       0.95      0.94      0.94   1874994\n",
      "weighted avg       0.95      0.94      0.94   1874994\n",
      "\n",
      "Bad Model Cross-Validation Accuracy:  0.9439358198954532\n",
      "Tuned Decision Tree Accuracy:  0.9996895990067168\n",
      "Tuned Decision Tree Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    937118\n",
      "           1       1.00      1.00      1.00    937876\n",
      "\n",
      "    accuracy                           1.00   1874994\n",
      "   macro avg       1.00      1.00      1.00   1874994\n",
      "weighted avg       1.00      1.00      1.00   1874994\n",
      "\n",
      "Tuned Decision Tree Cross-Validation Accuracy:  0.9992271982182337\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
